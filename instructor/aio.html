<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>Introduction to High Performance Computing: All in One View</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<script src="../assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="../assets/styles.css">
<script src="../assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="../favicons/incubator/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicons/incubator/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../favicons/incubator/favicon-16x16.png">
<link rel="manifest" href="../favicons/incubator/site.webmanifest">
<link rel="mask-icon" href="../favicons/incubator/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="white">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="black">
</head>
<body>
    <header id="top" class="navbar navbar-expand-md top-nav incubator"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="incubator-logo" alt="Lesson Description" src="../assets/images/incubator-logo.svg"><span class="badge text-bg-danger">
          <abbr title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.">
            <a href="https://docs.carpentries.org/resources/curriculum/lesson-life-cycle.html" class="external-link alert-link">
              <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
              Pre-Alpha
            </a>
            <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
          </abbr>
        </span>

      </div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text">
<li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul>
</li>
      </div>

      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
<li><button class="dropdown-item" type="button" onclick="window.location.href='../aio.html';">Learner View</button></li>
        </ul>
</div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Lesson Description" src="../assets/images/incubator-logo-sm.svg">
</div>
    <div class="lesson-title-md">
      Introduction to High Performance Computing
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
<li class="nav-item">
          <span class="lesson-title">
            Introduction to High Performance Computing
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/instructor-notes.html">Instructor Notes</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/images.html">Extract All Images</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
<hr>
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul>
</li>
      </ul>
</div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="../instructor/aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div>
<!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Introduction to High Performance Computing
</div>

<aside class="col-md-12 lesson-progress"><div style="width: %" class="percentage">
    %
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: %" aria-valuenow="" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text">
<li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul>
</li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="../aio.html">Learner View</a>
                      </div>
                    </div>
                  </div>
<!--/div.accordion-item-->
                </div>
<!--/div.accordion-flush-->
              </div>
<!--div.sidenav-view-selector -->
            </div>
<!--/div.col -->

            <hr>
</div>
<!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Schedule</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="introduction.html">1. Using Markdown</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="1_intro_to_hpc_systems.html">2. Introduction to HPC Systems</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="2_using_hpc_systems.html">3. Accessing and Using HPC Resources</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="3_job_scheduling.html">4. Introduction to Job Scheduling</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="4_programmatic_parallelism.html">5. Introduction to Programmatic Parallelism</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="5_hpc_technologies.html">6. Introduction to HPC Technologies</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width">
<div class="accordion accordion-flush lesson-resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="lesson-resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul>
<li>
                        <a href="../instructor/key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="../instructor/instructor-notes.html">Instructor Notes</a>
                      </li>
                      <li>
                        <a href="../instructor/images.html">Extract All Images</a>
                      </li>
                      <hr>
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
                    </ul>
</div>
                </div>
              </div>
            </div>
            <hr class="half-width lesson-resources">
<a href="../instructor/aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none">
<div class="d-grid gap-1">

            </div>
          </div>
<!-- /div.accordion -->
        </div>
<!-- /div.sidebar-inner -->
      </nav>
</div>
<!-- /div.sidebar -->
  </div>
<!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-extra.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <main id="main-content" class="main-content"><div class="container lesson-content">
        
        
<section id="aio-introduction"><p>Content from <a href="introduction.html">Using Markdown</a></p>
<hr>
<p>Last updated on 2025-09-25 |

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/episodes/introduction.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 12 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How do you write a lesson using Markdown and
<a href="https://carpentries.github.io/sandpaper/" class="external-link">sandpaper</a>?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Explain how to use markdown with The Carpentries Workbench</li>
<li>Demonstrate how to include pieces of code, figures, and nested
challenge blocks</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<hr class="half-width">
<p>This is a lesson created via The Carpentries Workbench. It is written
in <a href="https://pandoc.org/MANUAL.html" class="external-link">Pandoc-flavored Markdown</a>
for static files and <a href="https://rmarkdown.rstudio.com/" class="external-link">R
Markdown</a> for dynamic files that can render code into output. Please
refer to the <a href="https://carpentries.github.io/sandpaper-docs/" class="external-link">Introduction to The
Carpentries Workbench</a> for full documentation.</p>
<p>What you need to know is that there are three sections required for a
valid Carpentries lesson:</p>
<ol style="list-style-type: decimal">
<li>
<code>questions</code> are displayed at the beginning of the episode
to prime the learner for the content.</li>
<li>
<code>objectives</code> are the learning objectives for an episode
displayed with the questions.</li>
<li>
<code>key points</code> are displayed at the end of the episode to
reinforce the objectives.</li>
</ol>
<div id="accordionInstructor1" class="accordion instructor-note accordion-flush">
<div class="accordion-item">
<button class="accordion-button instructor-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseInstructor1" aria-expanded="false" aria-controls="collapseInstructor1">
  <h3 class="accordion-header" id="headingInstructor1">  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="edit-2"></i></div> Instructor Note </h3>
</button>
<div id="collapseInstructor1" class="accordion-collapse collapse" aria-labelledby="headingInstructor1" data-bs-parent="#accordionInstructor1">
<div class="accordion-body">
<p>Inline instructor notes can help inform instructors of timing
challenges associated with the lessons. They appear in the “Instructor
View”</p>
</div>
</div>
</div>
</div>
<div id="challenge-1-can-you-do-it" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="challenge-1-can-you-do-it" class="callout-inner">
<h3 class="callout-title">Challenge 1: Can you do it?</h3>
<div class="callout-content">
<p>What is the output of this command?</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">R<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">paste</span><span class="op">(</span><span class="st">"This"</span>, <span class="st">"new"</span>, <span class="st">"lesson"</span>, <span class="st">"looks"</span>, <span class="st">"good"</span><span class="op">)</span></span></code></pre>
</div>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Output </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[1] "This new lesson looks good"</code></pre>
</div>
</div>
</div>
</div>
</div>
<div id="challenge-2-how-do-you-nest-solutions-within-challenge-blocks" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="challenge-2-how-do-you-nest-solutions-within-challenge-blocks" class="callout-inner">
<h3 class="callout-title">Challenge 2: how do you nest solutions within
challenge blocks?</h3>
<div class="callout-content">

</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<p>You can add a line with at least three colons and a
<code>solution</code> tag.</p>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="figures">Figures<a class="anchor" aria-label="anchor" href="#figures"></a>
</h2>
<hr class="half-width">
<p>You can use standard markdown for static figures with the following
syntax:</p>
<p><code>![optional caption that appears below the figure](figure url){alt='alt text for accessibility purposes'}</code></p>
<figure><img src="https://raw.githubusercontent.com/carpentries/logo/master/Badge_Carpentries.svg" alt="Blue Carpentries hex person logo with no text." class="figure mx-auto d-block"><div class="figcaption">You belong in The Carpentries!</div>
</figure><div id="callout1" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div class="callout-inner">
<div class="callout-content">
<p>Callout sections can highlight information.</p>
<p>They are sometimes used to emphasise particularly important points
but are also used in some lessons to present “asides”: content that is
not central to the narrative of the lesson, e.g. by providing the answer
to a commonly-asked question.</p>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="math">Math<a class="anchor" aria-label="anchor" href="#math"></a>
</h2>
<hr class="half-width">
<p>One of our episodes contains <span class="math inline">\(\LaTeX\)</span> equations when describing how to
create dynamic reports with {knitr}, so we now use mathjax to describe
this:</p>
<p><code>$\alpha = \dfrac{1}{(1 - \beta)^2}$</code> becomes: <span class="math inline">\(\alpha = \dfrac{1}{(1 - \beta)^2}\)</span></p>
<p>Cool, right?</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Use <code>.md</code> files for episodes when you want static
content</li>
<li>Use <code>.Rmd</code> files for episodes when you need to generate
output</li>
<li>Run <code>sandpaper::check_lesson()</code> to identify any issues
with your lesson</li>
<li>Run <code>sandpaper::build_lesson()</code> to preview your lesson
locally</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-1_intro_to_hpc_systems"><p>Content from <a href="1_intro_to_hpc_systems.html">Introduction to HPC Systems</a></p>
<hr>
<p>Last updated on 2025-11-04 |

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/episodes/1_intro_to_hpc_systems.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 0 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What is a High Performance Computing cluster?</li>
<li>What is the difference between an HPC cluster and the cloud?</li>
<li>How can an HPC cluster help me with my research?</li>
<li>What HPC clusters are available to me and how do I get access to
them?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Describe the purpose of an HPC system and what it does</li>
<li>List the benefits of using an HPC system</li>
<li>Identify how an HPC system could benefit you</li>
<li>Summarise the typical arrangement of an HPC system’s components</li>
<li>Differentiate between characteristics and features of HPC and
cloud-based systems</li>
<li>Summarise the capabilities of the NOCS HPC facilities</li>
<li>Summarise the key capabilities of Iridis 6 and Iridis X for NOCS
applications</li>
<li>Summarise key capabilities of national HPC resources and how to
access them</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="high-performance-computing">High Performance Computing<a class="anchor" aria-label="anchor" href="#high-performance-computing"></a>
</h2>
<hr class="half-width">
<figure><img src="../fig/Iridis_6.jpeg" class="noinvert figure mx-auto d-block" style="width:100.0%" alt="Iridis 6: One of Southampton’s High Performance Computing clusters"><div class="figcaption">Iridis 6: One of Southampton’s High Performance
Computing clusters</div>
</figure><p>High Performance Computing (HPC) refers to the use of powerful
computers and programming techniques to solve computationally intensive
tasks. An HPC cluster, or supercomputer, is one which harnesses the
<strong>aggregated</strong> power of groups of advanced computing
systems. These high performance computers are grouped together in a
network as a unified system, hence the name cluster. HPC clusters
provide extremely high computational capabilities, significantly
surpasssing that of a general personal computer.</p>
<div id="callout1" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div class="callout-inner">
<div class="callout-content">
<p>Can you think of any computational research problems that could
benefit from the aggregated computational power of High Performance
Computing? Discuss it with your colleagues.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>Here are some computation research examples where HPC could be of
benefit: - A oceanography research student is modelling ocean
circulation by processing seismic reflection datasets. They have
thousands of these datasets - but each processing run takes an hour.
Running the model on a laptop will take over a month! In this research
problem, final results are calculated after all 1000 models have run,
but typically only one model is run at a time (in serial) on the laptop.
Since each of the 1000 runs is independent of all others, and given
enough computers, it’s theoretically possible to run them all at once
(in parallel).</p>
<ul>
<li><p>The seismic reflection datasets are extremely large and the
researcher is already finding it challenging to process the datasets on
their computer. The researcher has just received datasets that are 10
times as large - analysing these larger datasets will certainly crash
their computer. In this research problem, the calculations required
might be impossible to speed up by adding more computers, but a computer
with more memory would be required to analyse the much larger future
data set.</p></li>
<li><p>An ocean modeller is using a numerical modelling system such as
NEMO that supports parallel computation. While this option has not been
used previously, moving from 2D to fully 3D ocean simulations has
significantly increased the run time. In such models, calculations
within each ocean subdomain are largely independent, allowing them to be
solved simultaneously across processors while exchanging boundary
information between adjacent regions. Because 3D simulations involve far
more data and calculations, distributing the workload across multiple
processors or computers connected via a shared network can substantially
reduce runtime and make large-scale ocean simulations
practical.</p></li>
</ul>
</div>
</div>
</div>
</div>
<p>HPC clusters fundamentally perform simple numerical computations, but
on an extremely large scale. In our examples we can see where HPC
clusters excel, using hundreds or thousands of processors to complete a
numerical task that would take a desktop or laptop days, months or years
to complete. They can also tackle problems that are too large or complex
for a PC to fit in their memory, such as modelling the ocean dynamics or
the Earth’s climate.</p>
<p><strong>High Performance Computing allows you as researchers to scale
up your computational research and data processing, enabling you to do
more research or to solve problems that would be infeasible to solve on
your own computer.</strong></p>
</section><section><h2 class="section-heading" id="hpc-vs-pc">HPC vs PC<a class="anchor" aria-label="anchor" href="#hpc-vs-pc"></a>
</h2>
<hr class="half-width">
<p>Before we discuss High Performance Computing clusters in more detail
let’s start with a computational resource we are all familiar with, the
PC:</p>
<div class="section level3">
<h3 id="pc">PC<a class="anchor" aria-label="anchor" href="#pc"></a>
</h3>
<table style="width:100%; border-collapse:collapse; margin-bottom:1em;" class="table"><tr>
<!-- Image column --><td style="width:240px; vertical-align:top; text-align:center;">
<img src="../fig/laptop.svg" width="220" alt="Your PC is your local computing resource, good for small computational tasks." class="figure">
</td>
<!-- Text column -->
<td style="vertical-align:top; padding-left:20px;">
<p>
Your PC is your local computing resource, good for small computational
tasks. It is flexible, easy to set-up and configure for new tasks,
though it has limited computational resources.
</p>
<p>
Let’s dissect what resources programs running on a laptop require:
</p>
<ul>
<li>
A keyboard and/or touchpad is used to tell the computer what to do
(Input)
</li>
<li>
The internal computing resources Central Processing Unit (CPU) and
Memory are used to perform calculations
</li>
<li>
Display depicts progress and results (Output); alternatively, both input
and output can be done using data stored on Disk or on a Network
</li>
</ul>
</td>
</tr></table>
</div>
<div class="section level3">
<h3 id="if-our-pc-isnt-powerful-enough">If Our PC isnt Powerful Enough?<a class="anchor" aria-label="anchor" href="#if-our-pc-isnt-powerful-enough"></a>
</h3>
<figure><img src="../fig/server.svg" style="width:20.0%" alt="Outsourcing Computational Tasks: many of the tasks we perform daily using computers are outsourced to remote servers" class="figure mx-auto d-block"><div class="figcaption">Outsourcing Computational Tasks: many of the
tasks we perform daily using computers are outsourced to remote
servers</div>
</figure><p>When the task to solve becomes too computationally heavy, the
operations can be out-sourced from your local laptop or desktop to
elsewhere.</p>
<p>Take for example the task to find the directions for your next
conference. The capabilities of your laptop are typically not enough to
calculate that route in real time, so you use a website, which in turn
runs on a computer that is almost always a machine that is not in the
same room as you are. Such a remote machine is generically called a
server.</p>
<p>The internet made it possible for these data centers to be far remote
from your laptop. The server itself has no direct display or input
methods attached to it. But most importantly, it has much more storage,
memory and compute capacity than your laptop will ever have. However,
you still need a local device (laptop, workstation, mobile phone or
tablet) to interact with this remote machine.</p>
<p>There is a direct parallel between this and running computational
workloads on HPC clusters, in that you outsource computational tasks to
a remote computer.</p>
<p>However there is a distinct difference between the “cloud” and an HPC
cluster. What people call the cloud is mostly a web-service where you
can rent such servers by providing your credit card details and by
clicking together the specs of a remote resource. The cloud is a generic
term commonly used to refer to remote computing resources of any kind –
that is, any computers that you use but are not right in front of you.
Cloud can refer to machines serving websites, providing shared storage,
providing web services (such as e-mail or social media platforms), as
well as more traditional “compute” resources.</p>
<p>HPC systems are more static and rigidly structured than cloud
systems, and follow consistent patterns in how they’re deployed, whereas
cloud infrastructures tend to be much more flexible and “user-led” in
their configurations and provisioning.</p>
</div>
<div class="section level3">
<h3 id="hpc-cluster">HPC Cluster<a class="anchor" aria-label="anchor" href="#hpc-cluster"></a>
</h3>
<p>If the computational task or analysis is too large or complex for a
single server, larger agglomerations of servers are used. These HPC
systems are known as <strong>supercomputers</strong>, or described as
<strong>HPC clusters</strong> as they are made up of a cluster of
computers, or compute nodes.</p>
<p>Distinct to the cloud, these clusters are networked together and
share a common purpose to solve tasks that might otherwise be too big
for any one computer. Each individual compute node is typically a lot
more powerful than any PC - i.e. more memory, many more and faster CPU
cores. However in parallel to the cloud you access HPC clusters
remotely, through the internet.</p>
<p>The figure below shows the basic architecture of an HPC cluster.</p>
<figure><img src="../fig/HPC.png" style="width:80.0%" alt="High Performance Computing System Architecture: Simplified schematic of an HPC cluster." class="figure mx-auto d-block"><div class="figcaption">High Performance Computing System Architecture:
Simplified schematic of an HPC cluster.</div>
</figure><p>Lets go through each part of the figure:</p>
<div class="section level4">
<h4 id="interactive-login-nodes">Interactive Login Nodes<a class="anchor" aria-label="anchor" href="#interactive-login-nodes"></a>
</h4>
<p>When you are given an account on an HPC cluster you will get some
login credentials. Using these credentials you can remotely log-on to of
the interactive login nodes from your local PC over the internet. There
may be several login nodes, to make sure that all the users are not
trying to access one single machine at the same time.</p>
<p>Once you have logged onto the login node you can now run HPC
workloads, or jobs, on the HPC cluster. <strong>BUT you typically do not
directly access the CPU/GPU cores that do the hard work</strong>.
Supercomputers tend to operate in batch mode, where you submit your
workload to a resource manager which places it in a queue (resource
management and job submission will be discussed in more detail later).
The login node is where you prepare and submit your HPC jobs to the
queue to be scheduled to run.</p>
<p>The login nodes are used for:</p>
<ul>
<li>Interactive access point to the HPC resources.</li>
<li>Transferring data onto/off the system.</li>
<li>Compiling code and lightweight development tasks.</li>
<li>Preparing and submitting HPC workload job scripts to the
scheduler.</li>
<li>Running short lightweight scripts for setup or testing.</li>
<li>
<strong>Not for heavy computation</strong> — they have limited
resources, so running heavy computation here will affect other
users!</li>
</ul>
</div>
<div class="section level4">
<h4 id="compute-nodes">Compute Nodes<a class="anchor" aria-label="anchor" href="#compute-nodes"></a>
</h4>
<p>The compute nodes are the core of the system, and provide the system
resources to execute user jobs. They contain the thousands of processing
units and memory, working in parallel, to run the HPC workloads. They
are connected to one another through a high speed interconnect, so that
the communication time between the processors on separate nodes impacts
program run times as little as possible.</p>
<p>An HPC system may be made up of different types of compute node, for
example a typical HPC system may have:</p>
<ul>
<li>
<strong>Batch CPU Nodes</strong>: standard, general purpose, batch
CPU nodes for executing parallel workloads. ( Tens/Hundreds of CPUs per
node. Moderate RAM - hundreds of GBs)</li>
<li>
<strong>High-mem</strong>: nodes with similar CPUs to the standard
nodes, but large amounts of memory (TBs of memory)</li>
<li>
<strong>GPU nodes</strong>: containing accelerators for highly
parallel workloads e.g. AI training and inference, image processing and
dense linear algebra.</li>
<li>
<strong>Interactive/Visualisation</strong>: nodes allowing users to
run computationally intensive tasks interactively, such as data
visualisation.</li>
</ul>
</div>
<div class="section level4">
<h4 id="storage">Storage<a class="anchor" aria-label="anchor" href="#storage"></a>
</h4>
<p>These nodes are equipped with large disk arrays to manage the vast
amounts of data produced by HPC workloads. In most systems, multiple
storage nodes and disk arrays are linked together to form a parallel
file system, designed to handle the high input/output (I/O) demands of
large-scale computations. Users do not access storage nodes directly;
instead, their file systems are mounted on the login and compute nodes,
allowing access to data across the cluster.</p>
</div>
</div>
<div class="section level3">
<h3 id="hpc-vs-pc-1">HPC vs PC<a class="anchor" aria-label="anchor" href="#hpc-vs-pc-1"></a>
</h3>
<p>OK, now we have had a look at what makes up the basic components of
an HPC cluster let’s summarise the key features and differences between
your personal computer and an HPC cluster.</p>
<table class="table">
<colgroup>
<col width="13%">
<col width="38%">
<col width="48%">
</colgroup>
<thead><tr class="header">
<th><strong>Feature</strong></th>
<th><strong>Local PC</strong></th>
<th><strong>HPC Cluster</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Hardware</strong></td>
<td>Single standalone computer</td>
<td>Many interconnected compute nodes forming one system</td>
</tr>
<tr class="even">
<td><strong>Processors (CPU)</strong></td>
<td>Few cores (4–16 typical)</td>
<td>Many CPUs per node; hundreds or thousands of cores total across the
cluster</td>
</tr>
<tr class="odd">
<td><strong>Memory (RAM)</strong></td>
<td>Limited (8–128 GB)</td>
<td>Large aggregated memory (hundreds GB – several TB)</td>
</tr>
<tr class="even">
<td><strong>GPU (Accelerators)</strong></td>
<td>Typically one consumer or workstation GPU (e.g., NVIDIA RTX)</td>
<td>Typically can have multiple high-end GPUs on GPU nodes (e.g., NVIDIA
A100/H100), designed for massive parallel workloads</td>
</tr>
<tr class="odd">
<td><strong>Storage</strong></td>
<td>Local SSD/HDD; limited capacity</td>
<td>Shared large capacity high-speed parallel file system, and local SSD
on compute nodes</td>
</tr>
<tr class="even">
<td><strong>Networking</strong></td>
<td>Standard Ethernet; used mainly for internet or file sharing</td>
<td>High-speed interconnects for low-latency communication</td>
</tr>
<tr class="odd">
<td><strong>Maintenance</strong></td>
<td>User-maintained</td>
<td>Admin-maintained; centrally monitored and secured</td>
</tr>
<tr class="even">
<td><strong>Storage Access</strong></td>
<td>Local file access only</td>
<td>Shared network storage accessible to all nodes</td>
</tr>
<tr class="odd">
<td><strong>Typical Use Case</strong></td>
<td>Small-scale data analysis, development, or prototyping</td>
<td>Large-scale simulations, data-intensive computing, ML/AI
training</td>
</tr>
<tr class="even">
<td><strong>User Interaction</strong></td>
<td>Direct, interactive sessions largely GUI based</td>
<td>Typically accessed through the command line; Batch jobs submitted to
queue; limited interactive use</td>
</tr>
</tbody>
</table>
</div>
</section><section><h2 class="section-heading" id="the-hpc-landscape">The HPC Landscape<a class="anchor" aria-label="anchor" href="#the-hpc-landscape"></a>
</h2>
<hr class="half-width">
<p>HPC facilities are divided into tiers, with larger HPC clusters being
categorised in higher tiers.</p>
<figure><img src="../fig/tiers.png" style="width:80.0%" alt="High Performance Computing Landscape: In the UK HPC facilities are divided into tiers based upon their size." class="figure mx-auto d-block"><div class="figcaption">High Performance Computing Landscape: In the UK
HPC facilities are divided into tiers based upon their size.</div>
</figure><p>In the UK there are three tiers, with an additional highest tier for
continental systems:</p>
<ul>
<li>Tier 3: Local single institution supercomputers aimed towards
researchers at one institution. At the University of Southampton we have
the Iridis HPC cluster.</li>
<li>Tier 2: Layer of HPC clusters that sit above the Tier 3, or
University systems, and are larger or more specialised than most
University systems. These are facilities that fill the gap between tier
3 and tier 1 facilities.</li>
<li>Tier 1: Nationally leading HPC clusters.</li>
<li>Tier 0: European facilities with petaflop systems, and the best
across a continent. The Partnership for Advanced Computing in Europe
(PRACE) provides access to the 8 Tier-0 systems in Europe.</li>
</ul></section><section><h2 class="section-heading" id="tier-3-local-hpc-clusters">Tier 3: Local HPC Clusters<a class="anchor" aria-label="anchor" href="#tier-3-local-hpc-clusters"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="iridis-6-iridis-x">Iridis 6 &amp; Iridis X<a class="anchor" aria-label="anchor" href="#iridis-6-iridis-x"></a>
</h3>
<p>The local tier 3 system at the University of Southampton is known as
Iridis, which is comprised of two separate clusters known as
<strong>Iridis 6</strong> &amp; and <strong>Iridis X</strong>.</p>
<p>Iridis 6 is the University’s CPU based HPC cluster, intended for
running large parallel, multi-node, CPU based workloads. It comprised of
26,000+ AMD CPUs:</p>
<div id="callout2" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div class="callout-inner">
<div class="callout-content">
<p><strong>Iridis 6 Specification</strong></p>
<ul>
<li>134 Standard Compute Nodes
<ul>
<li>Dual-socket AMD EPYC 9654 (2×96 cores) → 192 cores per node</li>
<li>750 GB RAM (≈650 GB usable)</li>
</ul>
</li>
<li>6 Compute Nodes (EPYC 9684X)
<ul>
<li>Dual-socket AMD EPYC 9684X (2×96 cores) → 192 cores per node</li>
<li>650 GB usable memory per node</li>
</ul>
</li>
<li>4 High-Memory Nodes
<ul>
<li>Dual-socket AMD EPYC 9654 (2×96 cores) → 192 cores per node</li>
<li>3 TB RAM (≈2.85 TB usable)</li>
</ul>
</li>
<li>3 Login Nodes
<ul>
<li>Dual-socket AMD EPYC 9334 (2×32 cores) → 64 cores per node</li>
<li>64 GB RAM limit and 2 CPU per-user limit on login nodes</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
<p>Iridis X an hetereogeneous GPU cluster encompassing the University’s
GPU offering:</p>
<div id="callout3" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div class="callout-inner">
<div class="callout-content">
<p><strong>Iridis X Specification</strong></p>
<ul>
<li>AMD mi300x: 1 node — 128 CPU, 8× MI300X (192 GB each), 2.3 TB
RAM</li>
<li>NVIDIA H200:
<ul>
<li>Quad h200: 4 nodes — 48 CPU, 4× H200 (141 GB each), 1.5 TB RAM per
node</li>
<li>Dual h200: 2 nodes — 48 CPU, 2× H200 (141 GB each), 768 GB RAM per
node</li>
</ul>
</li>
<li>NVIDIA A100:
<ul>
<li>12 nodes — 48 CPU (Intel Xeon Gold), 2× A100 (80 GB each), 4.5 TB
RAM per node</li>
<li>1 Maths Node (Can be scavenged when idle)</li>
</ul>
</li>
<li>NVIDIA L40: 1 node — 48 CPU, 8× L40 (48 GB each), 768 GB RAM</li>
<li>NVIDIA L4: 2 nodes — 48 CPU, 8× L4 (24 GB each), 768 GB RAM per
node</li>
<li>CPU Only:
<ul>
<li>AMD Dual AMD EPYC 7452: : 74 nodes (64 CPU), 240 GB RAM per
node</li>
<li>AMD Dual AMD EPYC 7502 Serial Partition : 16 nodes (64 CPU), 240 GB
RAM per node</li>
</ul>
</li>
</ul>
<p>There is also departmental cluster within Iridis X, known as Swarm.
It is for the use of the Electronics and Computer Science department,
but it can be scavenged (i.e. used when idle). It contains:</p>
<ul>
<li>NVIDIA A100: 5 nodes — 96 CPU, 4× A100 SXM (80 GB each), 900 GB RAM
per node</li>
<li>NVIDIA H100: 2 nodes — 192 CPU, 8× H100 SXM (80 GB each), 1.9 TB RAM
per node</li>
</ul>
</div>
</div>
</div>
<p>You can find out more details about the system from the
<a href="https://sotonac.sharepoint.com/teams/HPCCommunityWiki" class="external-link">HPC
Community Wiki</a>, and to get access to the system there is a
<a href="https://sotonac.sharepoint.com/teams/HPCCommunityWiki/SitePages/Connecting-to-Iridis5.aspx" class="external-link">
short application form</a> to be filled in.</p>
<p>There is a team of HPC system adminstrators that look after Iridis,
including supporting the installation and maintenence of the software
you need. You can contact them through the
<a href="https://teams.microsoft.com/l/team/19%3A18c8baa70f8540d78455babffe11ad9c%40thread.tacv2/conversations?groupId=a0a40f99-c620-425f-8c12-a1216cf64cce&amp;tenantId=4a5378f9-29f4-4d3e-be89-669d03ada9d8" class="external-link">
HPC Community Teams</a>.</p>
</div>
</section><section><h2 class="section-heading" id="tier-2-regional-hpc-clusters">Tier 2: Regional HPC Clusters<a class="anchor" aria-label="anchor" href="#tier-2-regional-hpc-clusters"></a>
</h2>
<hr class="half-width">
<p>There are 9 EPSRC Tier 2 clusters in the UK. Access to the Tier 2
Facilities is free for academic researchers based in the UK, though
getting on to any particular system may be dependent on your institution
and the research you do. Typically getting compute time is through
public access calls, such as the
<a href="https://www.ukri.org/opportunity/access-to-high-performance-computing-facilities-autumn-2025/" class="external-link">UKRI
Access to High Performance Computing Facilities Call</a>. Which is a
“funding” call to get computational support for projects across the
entire UK Research and Innovation (UKRI) remit. Each system may have
also other routes to gaining access, such as including resources of the
facility in research grant proposals.</p>
<table style="width:100%; border-collapse:collapse; margin-bottom:1em;" class="table">
<tr>
<td style="width:120px; text-align:center; vertical-align:middle;">
<img src="../fig/hpc_system_logos/cirrus.png" width="150" class="figure">
</td>
<td style="padding-left:12px; vertical-align:middle;">
<strong><a href="https://www.epcc.ed.ac.uk/cirrus" target="_blank" class="external-link">Cirrus
(EPCC)</a></strong> — EPSRC Tier-2 HPC with 10,080-core SGI/HPE ICE XA
system plus 36 GPU nodes (each with 4× NVIDIA V100). Free or purchasable
academic access; industry access available.
</td>
</tr>
<tr>
<td style="text-align:center; vertical-align:middle;">
<img src="../fig/hpc_system_logos/baskerville.png" width="150" class="figure">
</td>
<td style="padding-left:12px; vertical-align:middle;">
<strong><a href="https://www.baskerville.ac.uk/" target="_blank" class="external-link">Baskerville
(University of Birmingham &amp; partners)</a></strong> — Tier-2 EPSRC
facility with 52 Lenovo Neptune servers, each with twin Intel IceLake
CPUs and 4× NVIDIA A100 GPUs. Access via EPSRC HPC calls or the
consortium.
</td>
</tr>
<tr>
<td style="text-align:center; vertical-align:middle;">
<img src="../fig/hpc_system_logos/isambard.jpeg" width="150" class="figure">
</td>
<td style="padding-left:12px; vertical-align:middle;">
<strong><a href="https://docs.isambard.ac.uk" target="_blank" class="external-link">Isambard 3
(GW4)</a></strong> — Tier-2 facility with a main cluster containing 384
NVIDIA Grace CPU Superchips, 72 cores per socket, along with MACS
(Multi-Architecture Comparison System) containing multiple different
examples of architecture for testing/benchmarking/development. Free for
EPSRC-domain academics; purchasable and industry access available.
</td>
</tr>
<tr>
<td style="text-align:center; vertical-align:middle;">
<img src="../fig/hpc_system_logos/csd3.jpeg" width="150" class="figure">
</td>
<td style="padding-left:12px; vertical-align:middle;">
<strong><a href="https://www.csd3.cam.ac.uk/" target="_blank" class="external-link">CSD3
(Cambridge)</a></strong> — Data-centric Tier-2 HPC for simulation and
analysis, operated across multiple institutions. Access through EPSRC
calls for academics and industry users.
</td>
</tr>
<tr>
<td style="text-align:center; vertical-align:middle;">
<img src="../fig/hpc_system_logos/sulis.png" width="150" class="figure">
</td>
<td style="padding-left:12px; vertical-align:middle;">
<strong><a href="https://sulis.ac.uk/" target="_blank" class="external-link">Sulis (HPC
Midlands+)</a></strong> — Tier-2 HPC for ensemble and high-throughput
workflows using containerisation for scalable computing. Access via
EPSRC calls or the Midlands+ consortium.
</td>
</tr>
<tr>
<td style="text-align:center; vertical-align:middle;">
<img src="../fig/hpc_system_logos/jade.png" width="150" class="figure">
</td>
<td style="padding-left:12px; vertical-align:middle;">
<strong><a href="https://www.jade.ac.uk/" target="_blank" class="external-link">Jade (Joint
Academic Data Science Endeavour) </a></strong> — EPSRC Tier-2 deep
learning system built on NVIDIA DGX-1 with 8× Tesla P100 GPUs linked by
NVLink. Free for EPSRC academics; paid and industry access available.
</td>
</tr>
<tr>
<td style="text-align:center; vertical-align:middle;">
<img src="../fig/hpc_system_logos/mmm_hub.png" width="150" class="figure">
</td>
<td style="padding-left:12px; vertical-align:middle;">
<strong><a href="https://mmmhub.ac.uk/" target="_blank" class="external-link">MMM Hub (Materials
and Molecular Modelling Hub) </a></strong> — Tier-2 supercomputing
facility for materials and molecular modelling, led by UCL with partners
in the Thomas Young Centre and SES Consortium. Available UK-wide.
</td>
</tr>
<tr>
<td style="text-align:center; vertical-align:middle;">
<img src="../fig/hpc_system_logos/nihpc.png" width="150" class="figure">
</td>
<td style="padding-left:12px; vertical-align:middle;">
<strong><a href="https://www.ni-hpc.ac.uk/" target="_blank" class="external-link">NI-HPC</a></strong>
— “Kelvin2” Tier-2 cluster supporting neuroscience, chemistry, and
precision medicine with 60×128-core AMD nodes, 4 hi-memory nodes, and
32× NVIDIA V100s. Fast-track access.
</td>
</tr>
<tr>
<td style="text-align:center; vertical-align:middle;">
<img src="../fig/hpc_system_logos/bede.png" width="150" class="figure">
</td>
<td style="padding-left:12px; vertical-align:middle;">
<strong><a href="https://n8cir.org.uk/supporting-research/facilities/nice/" target="_blank" class="external-link">Bede
at N8 CIR</a></strong> — EPSRC Tier-2 HPC with 32 IBM POWER9 nodes (each
4× NVIDIA V100 GPUs) plus 4 NVIDIA T4 nodes for AI inference. Access via
EPSRC calls or N8 partner universities.
</td>
</tr>
</table></section><section><h2 class="section-heading" id="tier-1-national-hpc-systems">Tier 1: National HPC Systems<a class="anchor" aria-label="anchor" href="#tier-1-national-hpc-systems"></a>
</h2>
<hr class="half-width">
<p>There are four National HPC facilities in the UK, each of which have
different architecture and will be suitable for different computational
research problems.</p>
<table style="width:100%; border-collapse:collapse; margin-bottom:1em;" class="table">
<tr>
<td style="width:120px; text-align:center; vertical-align:middle;">
<img src="../fig/hpc_system_logos/archer2.png" width="150" class="figure">
</td>
<td style="padding-left:12px; vertical-align:middle;">
<strong><a href="https://www.archer2.ac.uk/" target="_blank" class="external-link">ARCHER2</a></strong>
— the UK’s national supercomputing service offers a capability resource
for running very large parallel jobs. Based around an HPE Cray EX
supercomputing system with an estimated peak performance of 28 PFLOP/s,
the machine will have 5,860 compute nodes, each with dual AMD EPYC Zen2
(Rome) 64 core CPUs at 2.2GHz, giving 750,080 cores in total. The
service includes a service desk staffed by HPC experts from EPCC with
support from HPE Cray. Access is free at point of use for academic
researchers working in the EPSRC and NERC domains. Users will also be
able to purchase access at a variety of rates.
</td>
</tr>
<tr>
<td style="text-align:center; vertical-align:middle;">
<img src="../fig/hpc_system_logos/dirac.png" width="150" class="figure">
</td>
<td style="padding-left:12px; vertical-align:middle;">
<strong><a href="https://www.dirac.ac.uk/" target="_blank" class="external-link">DiRAC</a></strong>
— HPC for particle physics and astronomy, comprising multiple
architectures. Including: Data Intensive Cambridge - DIRAC (746,496 GPU
Cores), Data Intensive Leicester - DIAL (40,288 CPU cores), Extreme
Scaling Edinburgh - ES (4,921,344 GPU Cores), Memory Intensive Durham -
DI (80,240 CPU Cores with 731TB memory). Free for STFC-domain academics;
purchasable and industry access available.
</td>
</tr>
<tr>
<td style="text-align:center; vertical-align:middle;">
<img src="../fig/hpc_system_logos/isambard.jpeg" width="150" class="figure">
</td>
<td style="padding-left:12px; vertical-align:middle;">
<strong><a href="https://docs.isambard.ac.uk/specs/#system-specifications-isambard-ai-phase-1" target="_blank" class="external-link">Isambard
AI</a></strong> — As well as the Isambard 3 tier 2 system the GW4 also
manages Isambard-AI: National AI Research Resource (AIRR), a tier 1 AI
HPC system aimed at supporting AI and GPU enabled computational
research. It is composed of 5448 GH200 Grace Hopper superchips
containing one Grace CPU and one Hopper H100 GPU. It is ranked 11th in
the TOP500 list of the fastest supercomputers in the world.
</td>
</tr>
<tr>
<td style="text-align:center; vertical-align:middle;">
<img src="../fig/hpc_system_logos/dawn.png" width="150" class="figure">
</td>
<td style="padding-left:12px; vertical-align:middle;">
<strong><a href="https://www.hpc.cam.ac.uk/d-w-n%20target=" target="_blank" class="external-link">Dawn</a></strong>
— The AI Research Resource (AIRR) also includes Dawn, a tier 1 AI HPC
cluster aimed at supporting AI and GPU enabled computational research.
The Cambridge Dawn facility is made up of 1,024 Intel Data Centre GPU
Max 1550 GPUs.
</td>
</tr>
</table>
<p>Access to the National Facilities is through public access calls:</p>
<ul>
<li>ARCHER2: access for UK acadmeics is typically through the
<a href="https://www.ukri.org/opportunity/access-to-high-performance-computing-facilities-autumn-2025/" class="external-link">UKRI
Access to High Performance Computing Facilities Call</a>.</li>
<li>AIRR (Isambard-AI &amp; DAWN): access for UK academics is typically
through the
<a href="https://www.gov.uk/government/publications/ai-research-resource/airr-gateway-route-ukri-guidance" class="external-link">AIRR
Gateway route</a>, offering up to 10,000 GPU hours, designed for
researchers from academia, industry, or other UK organisations.</li>
<li>DiRAC: access for UK academics is typically through the
<a href="https://dirac.ac.uk/getting-access/" class="external-link">STFC’s Resource Allocation
Committee</a> calls.</li>
</ul>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>High Performance Computing (HPC) combines many powerful computers
(nodes) into clusters that work together to solve large or complex
computational problems faster than a personal computer.</li>
<li>HPC is essential when problems are too big, data too large, or
computations too slow for a single machine.</li>
<li>HPC facilities in the UK are divided into tiers: the largest systems
categorised in higher tiers. The University of Southampton’s HPC system
is a local tier 3 facility and you can get access to use it.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-2_using_hpc_systems"><p>Content from <a href="2_using_hpc_systems.html">Accessing and Using HPC Resources</a></p>
<hr>
<p>Last updated on 2025-09-25 |

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/episodes/2_using_hpc_systems.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 0 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>Did you know you have to have this question section?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Summarise the process for applying for access to IRIDIS /
OpenOnDemand</li>
<li>Summarise how access to HPC systems is typically secured</li>
<li>Describe how to connect to an HPC system using an SSH client
program</li>
<li>Describe how to transfer files to and from an HPC system over an SSH
connection</li>
<li>Summarise best practices for managing generated research data</li>
<li>Explain how the shell environment changes when the module mechanism
loads or unloads packages</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>Lesson content goes here</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>You need a list of key points</li>
</ul>
</div>
</div>
</div></section><section id="aio-3_job_scheduling"><p>Content from <a href="3_job_scheduling.html">Introduction to Job Scheduling</a></p>
<hr>
<p>Last updated on 2025-11-04 |

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/episodes/3_job_scheduling.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 0 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What is a job scheduler and why is it needed?</li>
<li>What is the difference between a login node and a compute node?</li>
<li>How can I see the available resources and queues?</li>
<li>What is a job submission script?</li>
<li>How do I submit, monitor, and cancel a job?</li>
<li>How (and when) should I use an interactive job?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Describe briefly what a job scheduler does</li>
<li>Contrast when to run programs on an HPC login node vs running them
on a compute node</li>
<li>Summarise how to query the available resources on an HPC system</li>
<li>Describe a minimal job submission script and parameters that need to
be specified</li>
<li>Summarise how to submit a batch job and monitor it until
completion</li>
<li>Summarise the process for requesting and using an interactive
job</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>An HPC cluster has thousands of nodes shared by many users. A job
scheduler is the software that manages this, deciding who gets what
resources and when. It ensures that tasks run efficiently and fairly,
matching a job’s resource request to available hardware. On Iridis, the
scheduler is Slurm, but the concepts are transferable to other
schedulers such as PBS.</p>
<figure><img src="../fig/restaurant_queue_manager.svg" style="width:100.0%" alt="Queueing up to eat at a popular restaurant is like queueing up to run something on an HPC cluster." class="figure mx-auto d-block"><div class="figcaption">Queueing up to eat at a popular restaurant is
like queueing up to run something on an HPC cluster.</div>
</figure><p>The scheduler acts like a manager at a popular restaurant. You must
queue to get in, and you must wait for a table to become free. This is
why your jobs may sit in a queue before they start, unlike on your
computer. In this episode, we’ll look at what a job scheduler is and how
you interact with it to get your jobs running on Iridis.</p>
<section><h2 class="section-heading" id="can-i-run-jobs-on-the-login-nodes">Can I run jobs on the login nodes?<a class="anchor" aria-label="anchor" href="#can-i-run-jobs-on-the-login-nodes"></a>
</h2>
<hr class="half-width">
<p>On Iridis, and all HPC clusters, the login nodes are intended only
for light and short tasks such as editing files, managing data,
compiling code and submitting/monitoring jobs in the queue.</p>
<p>You must not run computationally intensive or long-running tasks on
them. Login nodes are a shared resource for all users to access the
system, and so running intensive jobs on them slows the system down for
everyone. Any such process will be ended automatically, and repeated
misuse may lead to your access to Iridis being restricted. To enforce
this, login nodes have strict resource limits. You are limited to 64 GB
of RAM and 2 CPUs (Iridis X also provides an NVIDIA L4 GPU).</p>
<p>All computationally intensive work must be submitted to the job
scheduler. This places your job in a queue, and Slurm will allocate
dedicated compute node resources to it when they become available. If
you are compiling a large, complex codebase which requires more
resources, or need to transfer large amounts of data, you should
probably perform the tasks on a compute node instead. You can do this by
submitting a job or by starting an interactive session, both of which we
will cover later.</p>
</section><section><h2 class="section-heading" id="querying-available-resources">Querying available resources<a class="anchor" aria-label="anchor" href="#querying-available-resources"></a>
</h2>
<hr class="half-width">
<p>Compute nodes in Slurm are grouped together and organised into
different <strong>partitions</strong>. You can think of a partition as
the actual queue for a certain set of hardware. Clusters are made up of
different types of compute nodes, e.g. some with lots of memory, some
with GPUs, some with restricted access, and some that are just
“standard” compute nodes. The partitions are how Slurm organises this
hardware. Each partition has its own rules, such as a maximum run time,
who can access the resources in it or a limit on the number of nodes
that can used at once. To find what the partitions are on Iridis 6 and
their current state, we can use the <code>sinfo</code> command:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="ex">[iridis6]$</span> sinfo <span class="at">-s</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="ex">PARTITION</span>             AVAIL  TIMELIMIT   NODES<span class="er">(</span><span class="ex">A/I/O/T</span><span class="kw">)</span> <span class="ex">NODELIST</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="ex">batch*</span>                   up 2-12:00:00      99/35/0/134 red<span class="pp">[</span><span class="ss">6001</span><span class="pp">-</span><span class="ss">6134</span><span class="pp">]</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="ex">highmem</span>                  up 2-12:00:00          3/1/0/4 gold<span class="pp">[</span><span class="ss">6001</span><span class="pp">-</span><span class="ss">6004</span><span class="pp">]</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="ex">worldpop</span>                 up 2-12:00:00          0/6/0/6 red<span class="pp">[</span><span class="ss">6135</span><span class="pp">-</span><span class="ss">6140</span><span class="pp">]</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="ex">scavenger</span>                up   12:00:00          0/6/0/6 red<span class="pp">[</span><span class="ss">6135</span><span class="pp">-</span><span class="ss">6140</span><span class="pp">]</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="ex">interactive_practical</span>    up   12:00:00          1/0/0/1 red6128</span></code></pre>
</div>
<p>The <code>-s</code> flag outputs a summarised version of this list.
Omitting this flag provides a full listing of nodes in each queue and
their current state, which gets quite messy.</p>
<p>We can see the availability of each partition/queue, as well as the
maximum time limit for jobs (in <code>days-hours:minutes:seconds</code>
format). For example, on the batch queue there is a two and a half day
limit, whilst the scavenger queue has a twelve hour limit. The *
appended to the batch partition name indicates it is the preferred
default queue. The NODES column indicates the number of nodes in a given
state,</p>
<table class="table">
<thead><tr class="header">
<th>Label</th>
<th>State</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>A</td>
<td>Active</td>
<td>These nodes are busy running jobs.</td>
</tr>
<tr class="even">
<td>I</td>
<td>Idle</td>
<td>These nodes are not running jobs.</td>
</tr>
<tr class="odd">
<td>O</td>
<td>Other</td>
<td>These nodes are down, or otherwise unavailable.</td>
</tr>
<tr class="even">
<td>T</td>
<td>Total</td>
<td>The total number of nodes in the partition.</td>
</tr>
</tbody>
</table>
<p>Finally, the NODELIST column is a summary of the nodes belonging to a
particular queue; if we didn’t use the <code>-s</code> option, we could
get a complete list of each node in each state. In this particular
instance, we can see that 35 nodes are idle in the batch partition, so
if that queue fits our needs we may decide to submit to that as there
are available resources.</p>
<p>We can find out more details about specific partitions by using the
<code>scontrol show</code> command, which lets us view more
configuration details of a particular partition. To see the breakdown of
the batch partition, we use:</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="ex">[iridis6]$</span> scontrol show partition=batch</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="va">PartitionName</span><span class="op">=</span>batch</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>   <span class="va">AllowGroups</span><span class="op">=</span>ALL <span class="va">DenyAccounts</span><span class="op">=</span>worldpop <span class="va">AllowQos</span><span class="op">=</span>ALL</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="ex">...</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="ex"> </span>  MaxTime=2-12:00:00 MinNodes=0</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="ex">...</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="ex"> </span>  State=UP TotalCPUs=25728 TotalNodes=134</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="ex">...</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a><span class="ex"> </span>  DefMemPerCPU=3350 MaxMemPerNode=650000</span></code></pre>
</div>
<p>This purposefully truncated output shows who does and doesn’t have
access (AllowGroups, DenyAccounts) as well as details about the
configuration and details of the nodes in the partition (e.g. MaxTime,
MinNodes, TotalNodes, TotalCPUs). Here, we can see accounts belonging to
the “worldpop” group do not have access to the batch partition.</p>
<p>To get more detail about a particular node in a partition we use:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="ex">[iridis6]$</span> scontrol show node=red6001</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="va">NodeName</span><span class="op">=</span>red6001 <span class="va">Arch</span><span class="op">=</span>x86_64 <span class="va">CoresPerSocket</span><span class="op">=</span>96</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="ex"> </span>  CPUAlloc=192 CPUEfctv=192 CPUTot=192</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="ex">...</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="ex"> </span>  RealMemory=770000 AllocMem=643200 FreeMem=531885 Sockets=2</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a><span class="ex"> </span>  State=ALLOCATED</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="ex">...</span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="ex"> </span>  Partitions=batch</span></code></pre>
</div>
<p>This provides a detailed summary of the node, including the number of
CPUs on it (CPUTot), if there are GPUs (Gres) as well as the state of
the node (State), the current resources allocated to a user (CPUAlloc,
AllocMem) and other interesting information.</p>
<div id="the-scavenger-partition" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="the-scavenger-partition" class="callout-inner">
<h3 class="callout-title">The scavenger partition</h3>
<div class="callout-content">
<p>The scavenger partition on Iridis allows you to use idle compute
nodes that you do not normally have access to, ensuring those resources
do not go to waste. However, this access is low-priority. If a user with
access to those nodes submits a job, your scavenger job will be
preempted. This means your job is automatically cancelled and put back
into the queue. The scheduler will try to run it again later when other
idle resources become available.</p>
<p>Because your job can be cancelled at any time, you should only use
this partition for testing or for code that can save its progress (a
technique known as <a href="https://en.wikipedia.org/wiki/Application_checkpointing" class="external-link">checkpointing</a>).
This way, you won’t lose work if your job is preempted.</p>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="job-submission-scripts">Job submission scripts<a class="anchor" aria-label="anchor" href="#job-submission-scripts"></a>
</h2>
<hr class="half-width">
<p>To submit a job to run, we have to write a <strong>submission
script</strong> which contains the commands that we want to run on a
compute node. This is almost always a bash script, containing special
<code>#SBATCH</code> directives that tells Slurm what resources you need
to run your job. A very minimal example looks something like this:</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co">#!/bin/bash</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="co">#SBATCH --partition=batch</span></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="co">#SBATCH --time=00:01:00</span></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a><span class="co">#SBATCH --nodes=1</span></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="co">#SBATCH --cpus-per-task=2</span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a><span class="co"># This is the command that will run</span></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a><span class="bu">pwd</span></span></code></pre>
</div>
<p>Let’s break down this Bash script. The first line we need to include
is the <code>#!/bin/bash</code> shebang, which let’s Slurm know the
script is a Bash script. The next four lines starting with
<code>#SBATCH</code> are instructions to Slurm which tell it the
resources we’ve requested to run the job. In this case, we have included
the minimum <em>batch directives</em> you should include to submit a
job: the partition to run on, how long the job needs to run, the number
of nodes we require and the number of CPUs. The table below shows a list
of the most commonly used directives.</p>
<table class="table">
<colgroup>
<col width="16%">
<col width="57%">
<col width="26%">
</colgroup>
<thead><tr class="header">
<th>Parameter</th>
<th>Description</th>
<th>Example Value</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><code>--job-name</code></td>
<td>Sets a name for your job.</td>
<td><code>--job-name=my_analysis</code></td>
</tr>
<tr class="even">
<td><code>--nodes</code></td>
<td>Requests a specific number of compute nodes.</td>
<td><code>--nodes=1</code></td>
</tr>
<tr class="odd">
<td><code>--ntasks</code></td>
<td>Requests a total number of tasks (e.g., MPI processes).</td>
<td><code>--ntasks=16</code></td>
</tr>
<tr class="even">
<td><code>--ntasks-per-node</code></td>
<td>Specifies the number of tasks to run on each node.</td>
<td><code>-ntasks-per-node=8</code></td>
</tr>
<tr class="odd">
<td><code>--cpus-per-task</code></td>
<td>Requests a number of CPU cores for each task (e.g., for OpenMP
threads).</td>
<td><code>--cpus-per-task=4</code></td>
</tr>
<tr class="even">
<td><code>--time</code></td>
<td>Sets the maximum wall-clock time for the job (HH:MM:SS).</td>
<td><code>--time=01:30:00</code></td>
</tr>
<tr class="odd">
<td><code>--partition</code></td>
<td>Specifies the queue (partition) to submit the job to.</td>
<td><code>--partition=highmem</code></td>
</tr>
<tr class="even">
<td><code>--gres</code></td>
<td>Requests generic resources, most commonly GPUs.</td>
<td><code>--gres=gpu:1</code></td>
</tr>
<tr class="odd">
<td><code>--output</code></td>
<td>Specifies the file to write the standard output (STDOUT) to.</td>
<td><code>--output=job_output.log</code></td>
</tr>
<tr class="even">
<td><code>--error</code></td>
<td>Specifies the file to write the standard error (STDERR) to.</td>
<td><code>--error=job_error.log</code></td>
</tr>
<tr class="odd">
<td><code>--mail-user</code></td>
<td>Your email address for job status notifications.</td>
<td><code>--mail-user=a.user@soton.ac.uk</code></td>
</tr>
<tr class="even">
<td><code>--mail-type</code></td>
<td>Specifies which events trigger an email (e.g., BEGIN, END, FAIL,
ALL).</td>
<td><code>--mail-type=END,FAIL</code></td>
</tr>
</tbody>
</table>
<p>More directives can be found in the <a href="https://slurm.schedmd.com/sbatch.html" class="external-link">Slurm
documentation</a>.</p>
<p>So why do we request <code>ntasks</code> or
<code>cpus-per-task</code>? We can think of a task in Slurm as being an
instance of a program. Some programs are designed to run one instance of
themselves, but use many CPU cores. For programs like this, we should
request one task and 16 CPUs.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co">#SBATCH --ntasks=1</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="co">#SBATCH --cpus-per-task=16</span></span></code></pre>
</div>
<p>Other programs are designed to run multiple independent instances
that work in parallel. For programs like this, we’d request 16 tasks and
with one CPU per task.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co">#SBATCH --ntasks=16</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="co">#SBATCH --cpus-per-task=1</span></span></code></pre>
</div>
<p>Finally, some programs have multiple instances each using many CPU
cores.</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co">#SBATCH --ntasks=4</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="co">#SBATCH --cpus-per-task=8</span></span></code></pre>
</div>
<p>The submission script contains everything the compute node needs to
run your program correctly, from start to finish. After the
<code>#SBATCH</code> parameters, which <em>have to</em> go before your
commands, you write <em>all</em> of the shell commands needed to prepare
the environment and launch your code, as if you were running it for the
very first time. We need to do this because jobs essentially run from a
blank slate. The environment is not configured, so we have to configure
it. This includes, but is obviously not limited to, setting environment
variables, loading software modules, activating virtual environments (if
required) and navigating to the correct directory.</p>
<p>A more complete submission script, for running a Python script, would
look something like this:</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="co">#!/bin/bash</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a><span class="co">#SBATCH --job-name=python-example</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="co">#SBATCH --partition=batch</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="co">#SBATCH --time=04:00:00</span></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="co">#SBATCH --nodes=1</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a><span class="co">#SBATCH --ntasks=1</span></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a><span class="co">#SBATCH --cpus-per-task=1</span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a><span class="co"># Optional: print useful job info</span></span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a><span class="bu">echo</span> <span class="st">"Running on host: </span><span class="va">$(</span><span class="fu">hostname</span><span class="va">)</span><span class="st">"</span></span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a><span class="bu">echo</span> <span class="st">"Job started at: </span><span class="va">$(</span><span class="fu">date</span><span class="va">)</span><span class="st">"</span></span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a><span class="bu">echo</span> <span class="st">"SLURM job ID: </span><span class="va">$SLURM_JOB_ID</span><span class="st">"</span></span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a><span class="bu">echo</span> <span class="st">"Number of CPUs: </span><span class="va">$SLURM_CPUS_PER_TASK</span><span class="st">"</span></span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a></span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a><span class="co"># Load required modules</span></span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a><span class="ex">module</span> purge</span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a><span class="ex">module</span> load python/3.11</span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a></span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a><span class="co"># Activate Python virtual environment</span></span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a><span class="bu">source</span> ~/myenv/bin/activate</span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a></span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a><span class="co"># Set any environment variables or configuration options</span></span>
<span id="cb8-24"><a href="#cb8-24" tabindex="-1"></a><span class="bu">export</span> <span class="va">PYTHONUNBUFFERED</span><span class="op">=</span>1</span>
<span id="cb8-25"><a href="#cb8-25" tabindex="-1"></a></span>
<span id="cb8-26"><a href="#cb8-26" tabindex="-1"></a><span class="co"># Move to job directory</span></span>
<span id="cb8-27"><a href="#cb8-27" tabindex="-1"></a><span class="bu">cd</span> <span class="va">$SLURM_SUBMIT_DIR</span></span>
<span id="cb8-28"><a href="#cb8-28" tabindex="-1"></a></span>
<span id="cb8-29"><a href="#cb8-29" tabindex="-1"></a><span class="co"># Run the Python script</span></span>
<span id="cb8-30"><a href="#cb8-30" tabindex="-1"></a><span class="ex">python</span> my_script.py <span class="at">--input</span> data/input.txt <span class="at">--output</span> results/output.txt</span></code></pre>
</div>
<p>In this example, <a href="../files/python_job.sh">python_job.sh</a>, we
used the following script: <a href="../files/my_script.py">my_script.py</a>. In the submission script,
you will notice that we have used environment variables starting with
<code>$SLURM_</code>. These are set by Slurm when a job starts running
on a compute node. A complete list of them have be found in the <a href="https://slurm.schedmd.com/sbatch.html#SECTION_OUTPUT-ENVIRONMENT-VARIABLES" class="external-link">Slurm
documentation</a>.</p>
<div id="no-internet-access-on-compute-nodes" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="no-internet-access-on-compute-nodes" class="callout-inner">
<h3 class="callout-title">No internet access on compute nodes</h3>
<div class="callout-content">
<p>On Iridis, the compute nodes <strong>do not</strong> have access to
the internet. If your job script tries to download files or access any
online resource, it will hang and eventually fail. You should run any
<em>short</em> tasks that require internet access (like downloading
datasets) on the login nodes before you submit your job, or in an Iridis
on Demand interactive session.</p>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="submitting-monitoring-and-cancelling-jobs">Submitting, monitoring and cancelling jobs<a class="anchor" aria-label="anchor" href="#submitting-monitoring-and-cancelling-jobs"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="submitting-jobs">Submitting jobs<a class="anchor" aria-label="anchor" href="#submitting-jobs"></a>
</h3>
<p>Once we have written our submission script, we submit it to the job
queue using the <code>sbatch</code> command, giving it the argument the
name of our submission script.</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="ex">[iridis6]$</span> sbatch example-job.sh</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a><span class="ex">Submitted</span> batch job 715860</span></code></pre>
</div>
<p>If all goes well, you should see some output which says “Submitted
batch job” followed by a job ID, which a unique ID given to the job.
We’ll use this ID to manage our job such as checking the status of it or
cancelling it.</p>
<div id="test-your-script-before-submitting-it" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="test-your-script-before-submitting-it" class="callout-inner">
<h3 class="callout-title">Test your script before submitting it</h3>
<div class="callout-content">
<p>It is always good practice to test your submission script before
submitting a large or long-running job. There is nothing more
frustrating than waiting hours for your job to start, only to have it
crash instantly because of a simple typo or error in the script.</p>
<p>A good way to do this is to submit a test job that requests minimal
resources, for example: <code>--nodes=1</code>,
<code>--cpus-per-task=1</code> and <code>--time=00:05:00</code>. These
small, short jobs usually have a much shorter queue time. The goal is
not to test your code at scale or get results; it is only to confirm
that the script successfully loads its modules, finds its files, and
launches the program without immediately failing. Another option would
be to use the scavenger partition, which tends to have shorter queue
times.</p>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="monitoring-jobs">Monitoring jobs<a class="anchor" aria-label="anchor" href="#monitoring-jobs"></a>
</h3>
<p>We can check on the status of jobs we’ve submitted by using the
<code>squeue</code> command. This will show us any jobs we have waiting
in the queue or are currently running. Let’s take a look in more detail.
To take a look at only our jobs, we use:</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="ex">[iridis6]$</span> squeue <span class="at">-u</span> <span class="va">$USER</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="ex">JOBID</span>   PARTITION  NAME      USER     ST  TIME  NODES  NODELIST<span class="er">(</span><span class="ex">REASON</span><span class="kw">)</span></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="ex">715860</span>  batch      example   ejp1v21  R   0:00  1      red6085</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a><span class="ex">715558</span>  batch      video_so  ejp1v21  PD  0:00  1      <span class="er">(</span><span class="ex">Dependency</span><span class="kw">)</span></span></code></pre>
</div>
<p>By using <code>-u $USER</code>, where <code>$USER</code> is the
environment variable containing our username, we only see our jobs. If
we used just <code>squeue</code>, we would see all the jobs which are
either currently in the queue or are running for all users and
partitions. We can also use <code>-j</code> to query specific job IDs.
However we choose to use <code>squeue</code>, it prints the details of
jobs including the partition, user and also the state of the job (in the
ST column). In this example, we can see two jobs. One is in R, or
RUNNING, state and another is in PD, or PENDING, state. A job will
typically go through the following states,</p>
<table class="table">
<colgroup>
<col width="6%">
<col width="10%">
<col width="83%">
</colgroup>
<thead><tr class="header">
<th>Label</th>
<th>State</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>PD</td>
<td>PENDING</td>
<td>The jobs might need to wait in a queue first before they can be
allocated to a node to run.</td>
</tr>
<tr class="even">
<td>R</td>
<td>RUNNING</td>
<td>The job is currently running.</td>
</tr>
<tr class="odd">
<td>CG</td>
<td>COMPLETING</td>
<td>The job is in the process of completing.</td>
</tr>
<tr class="even">
<td>CD</td>
<td>COMPLETED</td>
<td>The job has completed.</td>
</tr>
</tbody>
</table>
<p>For pending jobs, you will usually see a reason for why the job is
pending in the NODELIST(REASON) column. This can be for a variety of
reasons, such as the nodes requested for job not being available, that
there are jobs in front of it in the queue, or that the job depends on
another completing first. Once the job is running, the nodes that it is
running on will be displayed in this column instead. While the
<code>squeue</code> table lists the common states for a successful job,
jobs can also end in failure. You may see other states, such as F
(Failed) if your program terminated with an error, OOM (Out of Memory)
if it exceeded its memory request, or CA (Cancelled) if you or an
administrator stopped it.</p>
<p>If we want more detail about a job, we can use
<code>scontrol show</code> again:</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="ex">[iridis6]$</span> scontrol show jobid=715860</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a><span class="va">JobId</span><span class="op">=</span>715860 <span class="va">JobName</span><span class="op">=</span>example.sh</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>   <span class="va">UserId</span><span class="op">=</span>ejp1v21<span class="kw">(</span><span class="ex">32917</span><span class="kw">)</span> <span class="va">GroupId</span><span class="op">=</span>fp<span class="kw">(</span><span class="ex">245</span><span class="kw">)</span> <span class="va">MCS_label</span><span class="op">=</span>N/A</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>   <span class="ex">...</span></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>   <span class="va">JobState</span><span class="op">=</span>RUNNING <span class="va">Reason</span><span class="op">=</span>None <span class="va">Dependency</span><span class="op">=</span><span class="va">(</span>null<span class="va">)</span></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>   <span class="ex">...</span></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>   <span class="va">RunTime</span><span class="op">=</span>00:00:09 <span class="va">TimeLimit</span><span class="op">=</span>00:01:00 <span class="va">TimeMin</span><span class="op">=</span>N/A</span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>   <span class="va">SubmitTime</span><span class="op">=</span>2025-10-29T14:58:31 <span class="va">EligibleTime</span><span class="op">=</span>2025-10-29T14:58:31</span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>   <span class="va">StartTime</span><span class="op">=</span>2025-10-29T14:58:32 <span class="va">EndTime</span><span class="op">=</span>2025-10-29T14:59:32 <span class="va">Deadline</span><span class="op">=</span>N/A</span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a>   <span class="va">Partition</span><span class="op">=</span>batch <span class="ex">AllocNode:Sid=login6002:1385285</span></span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a>   <span class="va">NodeList</span><span class="op">=</span>red6086</span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a>   <span class="ex">...</span></span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a>   <span class="va">AllocTRES</span><span class="op">=</span>cpu=1,mem=3350M,node=1,billing=1</span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a>   <span class="ex">...</span></span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a>   <span class="va">Command</span><span class="op">=</span>/iridisfs/home/ejp1v21/example.sh</span>
<span id="cb11-16"><a href="#cb11-16" tabindex="-1"></a>   <span class="va">StdErr</span><span class="op">=</span>/iridisfs/home/ejp1v21/slurm-715860.out</span>
<span id="cb11-17"><a href="#cb11-17" tabindex="-1"></a>   <span class="va">StdOut</span><span class="op">=</span>/iridisfs/home/ejp1v21/slurm-715860.out</span></code></pre>
</div>
<p>This detailed output confirms the JobState is RUNNING (though it
could be PENDING if still in the queue or COMPLETED if it had already
finished). With this output we can see exactly how long the job has been
running (RunTime) against its maximum allowed time (TimeLimit). It also
provides a complete history, showing when the job was submitted
(SubmitTime), when it reached the front of the queue (EligibleTime), and
when it started running (StartTime).</p>
<p>The <code>scontrol</code> output also shows precisely where the job
is running and what resources it has (Partition, NodeList, AllocTRES).
It also tells us what script is being run (Command) and where the output
for the job will be stored (StdErr, Stdout).</p>
</div>
<div class="section level3">
<h3 id="cancelling-jobs">Cancelling jobs<a class="anchor" aria-label="anchor" href="#cancelling-jobs"></a>
</h3>
<p>Sometimes we’ll make a mistake and need to cancel a job. This can be
done with the <code>scancel</code> command, giving it the ID of the job
you want to cancel:</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="ex">[iridis6]$</span> scancel 715860</span></code></pre>
</div>
<p>A clean return of the command indicates that the request to cancel
the job was successful. It might take a minute for the job to disappear
from the queue, as Slurm cleans it up. If we need to do something a bit
more dramatic and cancel all of our jobs, both running and pending then
we can use the <code>-u</code> flag to specify the user jobs we want to
cancel,</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="ex">[iridis6]$</span> scancel <span class="at">-u</span> <span class="va">$USER</span></span></code></pre>
</div>
<p>We can also refine this to cancel only pending jobs, whilst letting
running ones finish by using the <code>-t</code> state flag.</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="ex">[iridis6]$</span> scancel <span class="at">-u</span> <span class="va">$USER</span> <span class="at">-t</span> PENDING</span></code></pre>
</div>
<div id="submit-monitor-and-cancel-a-python-example" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="submit-monitor-and-cancel-a-python-example" class="callout-inner">
<h3 class="callout-title">Submit, monitor and cancel a Python
example</h3>
<div class="callout-content">
<p>Now try all of this yourself with the Python example from earlier in
the episode. You should use the the Python script <a href="../files/my_script.py">my_script.py</a> and the submission script <a href="../files/python_job.sh">python_job.sh</a>.</p>
<p>Submit your job, check in on its status in the queue and then cancel
it. The job should run for around five minutes, giving you enough time
to do these three steps.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>First, submit the <code>python_job.sh</code> script using the
<code>sbatch</code> command.</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="ex">[iridis6]$</span> sbatch python_job.sh</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a><span class="ex">Submitted</span> batch job 715861</span></code></pre>
</div>
<p>Make a note of the Job ID (e.g., 715861) that is returned. Check the
status of your job using <code>squeue -u $USER</code>. You should see
your job listed, likely in the PD (Pending) state.</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="ex">[iridis6]$</span> squeue <span class="at">-u</span> <span class="va">$USER</span></span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a><span class="ex">JOBID </span>  PARTITION  NAME      USER     ST  TIME  NODES  NODELIST<span class="er">(</span><span class="ex">REASON</span><span class="kw">)</span></span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a><span class="ex">715861 </span> batch      python_job  ejp1v21  PD  0:00  1      <span class="er">(</span><span class="ex">Priority</span><span class="kw">)</span></span></code></pre>
</div>
<p>Finally, cancel the job using <code>scancel</code> and the Job ID you
noted.</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="ex">[iridis6]$</span> scancel 715861</span></code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="interactive-jobs">Interactive jobs<a class="anchor" aria-label="anchor" href="#interactive-jobs"></a>
</h2>
<hr class="half-width">
<p>We have so far been using Slurm to submit jobs to a queue and then
waiting for them to finish. However, on Iridis we can also start an
interactive jobs where we get direct access to compute nodes via a shell
session, letting us start the jobs directly from the command line. This
is incredibly useful for debugging code which isn’t working, or for
experimenting and testing, e.g. you may want to test your submission
script using <code>bash ./job-script.sh</code>.</p>
<p>To start an interactive session use the <code>sinteractive</code>
command. By default, this will give a single node for 2 hours, but this
can be changed with same job parameters in a job submission script,
e.g. <code>sinteractive --time=05:00:00 --cpus-per-task=4</code>,</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="ex">[iridisX]$</span> sinteractive <span class="at">--partition</span><span class="op">=</span>l4</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a><span class="ex">Waiting</span> for JOBID 731867 to start.......</span></code></pre>
</div>
<p>This will start an interactive session on the L4 partition on Iridis
X, for 2 hours with 1 CPU. If sufficient resources are available, the
interactive job will start immediately, otherwise, it will need to queue
to start. As resources may not be available immediately to satisfy the
requirements of an interactive job, it is normally only practical to use
interactive jobs for short jobs of a few hours or less, running on a
couple of nodes. You may also want to use <code>sinfo -s</code> to query
which partitions have idle nodes, and use those.</p>
<p>Once the interactive session has started, you are logged into the
node the job has been allocated and you can run commands from as if it
were a terminal session on your own computer. You can even use GUI
applications as long as X-forwarding has been setup correctly.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>The job scheduler (like Slurm) manages all user jobs to ensure fair
and efficient use of the cluster.</li>
<li>Login nodes are for light tasks (editing, compiling); compute nodes
are for running scheduled, intensive jobs.</li>
<li>Use <code>sinfo</code> and <code>scontrol</code> to query the status
of partitions (queues) and nodes.</li>
<li>A job script is a Bash script containing <code>#SBATCH</code>
directives (resource requests) and the commands to be run.</li>
<li>Use <code>sbatch</code> to submit a job, <code>squeue</code> to
monitor its status, and <code>scancel</code> to cancel it.</li>
<li>Use <code>sinteractive</code> to request a live terminal session on
a compute node for debugging or interactive work.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-4_programmatic_parallelism"><p>Content from <a href="4_programmatic_parallelism.html">Introduction to Programmatic Parallelism</a></p>
<hr>
<p>Last updated on 2025-10-22 |

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/episodes/4_programmatic_parallelism.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 0 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What is parallelisation and how does it improve performance?</li>
<li>What are the different types of parallelisation?</li>
<li>Why does synchronisation matter?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Describe the concept of parallelisation and its significance in
improving performance</li>
<li>Differentiate between parallelising programs via processes and
threads</li>
<li>Compare and contrast the operation and benefits of shared and
distributed memory systems</li>
<li>Define a race condition and how to avoid them</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>Parallel programming has been important to (scientific) computing for
decades as a way to decrease how long a piece of code takes to run
making more complex computations possible, such as in climate modelling,
pharmaceutical development, aircraft design, AI and machine learning,
and etc. Without parallelisation, these computations which would take
years to finish can instead be completed in hours or days! In this
episode, we will cover the foundational concepts of parallel
programming. But, before we get into the nitty-gritty details of
parallelisation frameworks and techniques, let’s first familiarise
ourselves with the key ideas behind parallel programming.</p>
<section><h2 class="section-heading" id="what-is-parallelisation">What is parallelisation?<a class="anchor" aria-label="anchor" href="#what-is-parallelisation"></a>
</h2>
<hr class="half-width">
<p>At some point you, or someone you know, has probably asked “how can I
make my code faster?” The answer to this question will depend on the
code, but there are a few approaches you might try:</p>
<ul>
<li>Optimise the code.</li>
<li>Move the computationally demanding parts of the code from a slower,
interpreted language, such as Python, to a faster, compiled language
such as C, C++ or Fortran.</li>
<li>Use a different theoretical/computational or approximate method
which requires less computation.</li>
</ul>
<p>All of these reduce the total amount of work the processor does.
Parallelisation takes a different approach: splitting the workload
across multiple processing units such as central processing units
(<strong>CPU</strong>s) or graphics processing units
(<strong>GPU</strong>s). Each processing unit works on a smaller batch
of work simultaneously. Instead of reducing the amount of work to be
done by, e.g. optimising our code, we instead have multiple processors
working on the task at the same time.</p>
<div class="section level3">
<h3 id="sequential-vs--parallel-computing">Sequential vs. parallel computing<a class="anchor" aria-label="anchor" href="#sequential-vs--parallel-computing"></a>
</h3>
<figure><img src="../fig/serial-and-parallel-progs.png" alt="On the left, a single processing unit executes one sequence of instructions for the whole problem. On the right, the problem is divided into independent tasks, each processed concurrently by separate processing units." class="figure mx-auto d-block"><div class="figcaption">On the left, a single processing unit executes
one sequence of instructions for the whole problem. On the right, the
problem is divided into independent tasks, each processed concurrently
by separate processing units.</div>
</figure><p>Traditionally, computers execute one instruction at a time, in the
sequence defined by the code you have written. In other words, your code
is compiled into a series of instructions which are executed one after
another. We call this serial execution.</p>
<p>With parallel computing, multiple instructions, from the same
program, are carried out at the same time on different processing units.
This means more work is being done at once, so we get the results
quicker than if we were running the same set of instructions
sequentially on a single processor. The process of changing sequential
code to parallel code is called parallelisation.</p>
<div id="painting-a-room" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="painting-a-room" class="callout-inner">
<h3 class="callout-title">Painting a room</h3>
<div class="callout-content">
<p>Parallel computing means dividing a job into tasks that can run at
the same time. Imagine painting four walls in a room. The problem is
painting the room. The tasks are painting each wall. The tasks are
independent, you don’t need to finish one wall before starting
another.</p>
<p>If there is only one painter, they must work on one wall at a time.
With one painter, painting the walls is <em>sequential</em>, because
they paint one wall at the time. But since each wall is independent, the
painter can switch between painting them in any order. This is
<em>concurrent</em> work, where they are making progress on multiple
walls over time, but not simultaneously.</p>
<p>With two or more painters, walls can be painted at the same time.
This is <em>parallel</em> work, because the painters are making painting
the room by painting multiple walls at the same time.</p>
<p>In this analogy, the painters represent CPU cores. The number of
cores limits how many tasks can run in parallel. Even if there are many
tasks, only as many can progress simultaneously as there are cores.
Managing many tasks with fewer cores is called concurrency.</p>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="key-parallelisation-concepts">Key parallelisation concepts<a class="anchor" aria-label="anchor" href="#key-parallelisation-concepts"></a>
</h2>
<hr class="half-width">
<p>There is, unfortunately, more to parallelisation than simply dividing
work across multiple processors. Whilst the idea of splitting tasks to
achieve faster results is <em>conceptually</em> simple, the practical
implementation is more complex. Adding additional CPU cores raises new
issues:</p>
<ul>
<li>If there are two cores, they might share the same RAM (shared
memory) or each have their own dedicated RAM (private memory). This
distinction affects how data can be accessed and shared between
processors.</li>
<li>In a shared memory setup, what happens if two cores try to read or
write the same memory location at the same time? This can cause a race
condition, where the outcome depends on the timing of operations.</li>
<li>How do we divide and distribute the workload evenly among the CPU
cores? Dividing the workload unevenly will result in inefficient
parallelisation.</li>
<li>How will the cores exchange data and coordinate their actions?
Additional mechanisms are required to enable this.</li>
<li>After the tasks are complete, where should the final results be
stored? Should they remain in the memory of one CPU core, be copied to a
shared memory area, or written to disk? Additionally, which core handles
producing the output?</li>
</ul>
<p>To answer these questions, we need to understand what a
<strong>process</strong> and what a <strong>thread</strong> is, how they
are different, and how they interact with the computer’s resources
(memory, file system, etc.).</p>
</section><section><h2 class="section-heading" id="processes">Processes<a class="anchor" aria-label="anchor" href="#processes"></a>
</h2>
<hr class="half-width">
<p>A process is an individual running instance of a software program.
Each process operates independently and possesses its own set of
resources, such as memory space and open files, managed by the operating
system. Because of this separation, data in one processes is typically
isolated and cannot be directly accessed by another process.</p>
<figure><img src="../fig/multiprocess.svg" alt="Multiple independent processes, each with their own private memory space, communicating through explicit message passing over a network." class="figure mx-auto d-block"><div class="figcaption">Multiple independent processes, each with their
own private memory space, communicating through explicit message passing
over a network.</div>
</figure><p>One approach to achieve parallel execution is by running multiple
coordinated processes at the same time. But what if one processes needs
information from another processes? Since processes are isolated and
have private memory spaces, information has to be explicitly
communicated by the programmer between processes. This is the role of
parallel programming frameworks and libraries such as <a href="https://www.mpi-forum.org/" class="external-link">MPI</a> (Message Passing Interface).
MPI provides a standardised library of functions that allow processes to
exchange messages, coordinate tasks and collectively work on a problem
together.</p>
<p>This style of parallelisation is the dominant form of parallelisation
on HPC systems. By combining MPI with a cluster’s job scheduler, it is
possible to launch and coordinate processes across many compute nodes.
Instead of having access to just a single CPU or computer, our code can
now use thousands or even tens of thousands of CPUs across many
computers which are connected together.</p>
</section><section><h2 class="section-heading" id="threads">Threads<a class="anchor" aria-label="anchor" href="#threads"></a>
</h2>
<hr class="half-width">
<p>A thread is a unit of execution which exists within a process. Unlike
processes, threads share their parent process’ resources, including
memory and open files, so they can directly read and write the same
memory space. This shared access means threads can exchange data faster,
since they do not have to communicate it between them.</p>
<figure><img src="../fig/multithreading.svg" alt="Multiple threads within a single process, sharing the same memory space and resources." class="figure mx-auto d-block"><div class="figcaption">Multiple threads within a single process,
sharing the same memory space and resources.</div>
</figure><p>By running multiple threads, over multiple CPU cores, a program can
coordinate for each thread to work on their own task(s). For example,
one thread may handle input/output whilst other threads perform some
number crunching, or multiple threads might process different parts of a
dataset simultaneously.</p>
<p>A major advantage of using threads is their relative ease of use
compared to processes. With frameworks such as <a href="https://www.openmp.org/" class="external-link">OpenMP</a>), which provides a set of
compiler extensions and libraries for paralleling code using threads,
existing code can be adapted for parallel execution with, often,
relatively small changes. Because threads share a memory space, there is
no need for explicit message-passing mechanisms (as required with
processes). However, this shared memory model introduces the possibility
of race conditions, where two or more threads attempt to update the same
data at once. Careful synchronisation is therefore required. It is
important to note, however, that threads are confined to a single
process and therefore to a single computer. Programs which are
parallelised using threads cannot span across compute nodes in a
cluster.</p>
</section><section><h2 class="section-heading" id="shared-vs-distributed-memory-parallelisation">Shared vs distributed memory parallelisation<a class="anchor" aria-label="anchor" href="#shared-vs-distributed-memory-parallelisation"></a>
</h2>
<hr class="half-width">
<p>When writing parallel programs, a key distinction is whether there is
a single shared memory space or if there are multiple private memory
spaces. These two models are called shared memory and distributed
memory.</p>
<figure><img src="../fig/memory-pattern.png" alt="Comparison of shared and distributed memory architectures: shared memory shows multiple processors accessing one memory pool, while distributed memory shows processors each with private memory connected by communication links." class="figure mx-auto d-block"><div class="figcaption">Comparison of shared and distributed memory
architectures: shared memory shows multiple processors accessing one
memory pool, while distributed memory shows processors each with private
memory connected by communication links.</div>
</figure><p>In a shared memory system, all processors (or cores) can directly
access and modify the same pool of memory. Changes made by one processor
are immediately visible to the others. This model aligns naturally with
parallelisation using <strong>threads</strong>, which exist within a
single process and share the parent process’ memory. However, shared
memory has limitations: if multiple threads try to update the same data
simultaneously, race conditions can occur. Correct results require
careful synchronisation. Programming models such as OpenMP (Open
Multi-Processing) provide mechanisms to divide work among threads and
synchronise access to shared data. In general, shared memory approaches
are generally limited to the cores within a single computer or node. The
advantage of shared memory is its simplicity, making it easier to
implement and debug. The main disadvantage is limited scalability, as
performance gains are constrained by the number of cores in a single
node and the complexity of synchronisation.</p>
<p>In a distributed memory system, each processor has its own private
memory. Data cannot be accessed directly by other processors, it must be
explicitly sent and received. This model aligns with parallelisation
using <strong>processes</strong> which each have their own private
memory space. Communication between processes is typically handled using
libraries such as MPI. Distributed memory programming requires more
effort than shared memory, but it enables programs to scale across
multiple nodes in a cluster. The advantage of distributed memory is its
high scalability, allowing computations across thousands of nodes. The
disadvantages include increased programming complexity and additional
overheads required for communication information, as data must be
explicitly exchanged between processes (private memory spaces).</p>
<p>The differences can be summarised:</p>
<ul>
<li>Accessibility: Shared memory allows direct access to a common memory
space. Distributed memory requires explicit communication for data
exchange.</li>
<li>Memory scope: Shared memory provides a global pool, while
distributed memory isolates each processor’s memory.</li>
<li>Consistency: In shared memory, changes are immediately visible to
all cores. In distributed memory, explicit synchronisation is needed to
keep results consistent.</li>
<li>Scalability: Shared memory is limited to one node. Distributed
memory scales to thousands of nodes.</li>
<li>Programming complexity: Shared memory models are simpler to use but
harder to scale. Distributed memory models scale well but require more
explicit programming.</li>
<li>Advantages/Disadvantages: Shared memory is easier to program , but
is limited in scale and prone to synchronisation issues. Distributed
memory scales to more cores, but is more complex and requires explicit
data communication.</li>
</ul>
<p>In sophisticated applications, a hybrid approach is used which
combines using processes to spread the workload across multiple nodes,
but uses shared-memory parallelisation on a node. This takes advantage
of the scalability of distributed memory, and the efficiency of using
shared-memory with threads.</p>
</section><section><h2 class="section-heading" id="synchronisation-and-race-conditions">Synchronisation and race conditions<a class="anchor" aria-label="anchor" href="#synchronisation-and-race-conditions"></a>
</h2>
<hr class="half-width">
<p>Synchronisation ensures that processing units can coordinate their
actions correctly, particularly when threads are accessing or modifying
shared data. Without proper synchronisation, multiple threads, for
example, might attempt to update the same variable simultaneously,
leading to unpredictable results known as a race condition.</p>
<p>In a shared memory system, synchronisation mechanisms such as
barriers, locks, and atomic operations are used to control access to
shared data and to coordinate work. A barrier ensures that threads have
reached a certain point before continuing, while locks prevent sections
of code from being executed simultaneously, preventing race conditions.
Atomic operations allow individual updates to shared variables without
interference, meaning only one thread can update a variable at once.
Proper use of these mechanisms ensures code correctness, maintaining
consistent and valid results.</p>
<p>In distributed memory systems, synchronisation is achieved by
coordinating communication between processes to order the workload and
manage data dependencies. Even though processes have their own private
memory space, race conditions can still occur if two processes write to
the same file. Effective synchronisation, whether with threads or
processes, is crucial for ensuring that parallel programs produce
correct, reproducible results.</p>
<div id="organising-the-painters" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="organising-the-painters" class="callout-inner">
<h3 class="callout-title">Organising the painters</h3>
<div class="callout-content">
<p>Imagine several painters working on the same set of walls. If each
painter tries to paint the same wall at the same time without
coordinating, they might overwrite each other’s work creating a mess.
This is like a race condition in parallel programming, where there is
simultaneous memory access modifying the same data.</p>
<p>To avoid this, painters might take turns for the shared wall, or
divide walls so each painter works independently. In programming,
mechanisms like barriers or atomic operations perform the same role:
they synchronise access to shared resources.</p>
<p>This coordination ensures that all parts of the task progress in the
right order, whether you are updating a shared variable, writing results
to disk, or aggregating data.</p>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>Parallelisation speeds up computation by dividing work across
multiple processing units.</li>
<li>Processes use private memory and communicate information explicitly
between them (distributed memory, e.g. MPI).</li>
<li>Threads share memory within a process and require synchronisation to
prevent race conditions.</li>
<li>Shared memory parallelisation is simpler but limited in scale.
Distributed memory scales better, but is more complex.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-5_hpc_technologies"><p>Content from <a href="5_hpc_technologies.html">Introduction to HPC Technologies</a></p>
<hr>
<p>Last updated on 2025-09-25 |

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/episodes/5_hpc_technologies.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 0 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>Did you know you have to have this question section?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Differentiate at a high level between the features of OpenMP, MPI,
CUDA and AI/ML approaches and what they are used for</li>
<li>Briefly summarise the main OpenMP compiler directives and what they
do</li>
<li>Describe how to compile and run an OpenMP program</li>
<li>Briefly summarise the main MPI message-passing features and how they
are used</li>
<li>Describe how to compile and run an MPI program</li>
<li>Describe the advantages and drawbacks for using a hybrid OpenMP/MPI
approach</li>
<li>Briefly summarise how a CUDA program is written</li>
<li>Describe why code scalability is important when using HPC
resources</li>
<li>Describe the differences between strong and weak scaling</li>
<li>Summarise the dangers of premature optimisation</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>Lesson content goes here</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul>
<li>You need a list of key points</li>
</ul>
</div>
</div>
</div></section>
</div>
    </main>
</div>
<!-- END  : inst/pkgdown/templates/content-extra.html -->

      </div>
<!--/div.row-->
      		<footer class="row footer mx-md-3"><hr>
<div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/README.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/carpentries/workbench-template-md/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/carpentries/workbench-template-md/" class="external-link">Source</a></p>
				<p><a href="https://github.com/carpentries/workbench-template-md/blob/main/CITATION.cff" class="external-link">Cite</a> | <a href="mailto:team@carpentries.org">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.17.1" class="external-link">sandpaper (0.17.1)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.9" class="external-link">pegboard (0.7.9)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.7" class="external-link">varnish (1.0.7)</a></p>
			</div>
		</footer>
</div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "LearningResource",
  "@id": "https://carpentries.github.io/workbench-template-md/instructor/aio.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/LearningResource/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "software, data, lesson, The Carpentries",
  "name": "All in One View",
  "creativeWorkStatus": "active",
  "url": "https://carpentries.github.io/workbench-template-md/instructor/aio.html",
  "identifier": "https://carpentries.github.io/workbench-template-md/instructor/aio.html",
  "dateCreated": "2025-11-04",
  "dateModified": "2025-11-04",
  "datePublished": "2025-11-04"
}

  </script><script>
		feather.replace();
	</script>
</body>
</html><!-- END:   inst/pkgdown/templates/layout.html-->

